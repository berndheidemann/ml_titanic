{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.idea',\n",
       " '.ipynb_checkpoints',\n",
       " 'firstTry.ipynb',\n",
       " 'foo.py',\n",
       " 'gender_submission.csv',\n",
       " 'neuralNet.ipynb',\n",
       " 'simpleRandomForest-withoutFastAI.ipynb',\n",
       " 'simpleRandomForest.ipynb',\n",
       " 'submission.csv',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'venv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCategorical(df):\n",
    "    for col_name in df.columns:\n",
    "        if(df[col_name].dtype == 'object'):\n",
    "            df[col_name]= df[col_name].astype('category')\n",
    "            df[col_name] = df[col_name].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertToCategorical(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Objekt-Spalten (alles au√üer Zahlen) zu categorical-Data machen und entsprechend kodieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>523</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  Ticket  \\\n",
       "0            1         0       3   108    1  22.0      1      0     523   \n",
       "1            2         1       1   190    0  38.0      1      0     596   \n",
       "2            3         1       3   353    0  26.0      0      0     669   \n",
       "3            4         1       1   272    0  35.0      1      0      49   \n",
       "4            5         0       3    15    1  35.0      0      0     472   \n",
       "\n",
       "      Fare  Cabin  Embarked  \n",
       "0   7.2500     -1         2  \n",
       "1  71.2833     81         0  \n",
       "2   7.9250     -1         2  \n",
       "3  53.1000     55         2  \n",
       "4   8.0500     -1         2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age            177\n",
       "Cabin            0\n",
       "Embarked         0\n",
       "Fare             0\n",
       "Name             0\n",
       "Parch            0\n",
       "PassengerId      0\n",
       "Pclass           0\n",
       "Sex              0\n",
       "SibSp            0\n",
       "Survived         0\n",
       "Ticket           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.Age.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_raw, test_raw) = train_test_split(df_raw, test_size=0.15, random_state=42)\n",
    "train_y=train_raw.Survived\n",
    "train_x=train_raw.drop('Survived', axis=1)\n",
    "test_y=test_raw.Survived\n",
    "test_x=test_raw.drop('Survived', axis=1)\n",
    "test_y=to_categorical(test_y, num_classes=2)\n",
    "train_y=to_categorical(train_y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=df.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 846 samples, validate on 45 samples\n",
      "Epoch 1/300\n",
      "846/846 [==============================] - 1s 1ms/step - loss: 1.0891 - acc: 0.7234 - val_loss: 1.2296 - val_acc: 0.6222\n",
      "Epoch 2/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4959 - acc: 0.8345 - val_loss: 1.2141 - val_acc: 0.6889\n",
      "Epoch 3/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4376 - acc: 0.8511 - val_loss: 1.3654 - val_acc: 0.6222\n",
      "Epoch 4/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3865 - acc: 0.8676 - val_loss: 1.4453 - val_acc: 0.6444\n",
      "Epoch 5/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.4007 - acc: 0.8440 - val_loss: 1.7698 - val_acc: 0.6667\n",
      "Epoch 6/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4145 - acc: 0.8522 - val_loss: 1.4686 - val_acc: 0.6889\n",
      "Epoch 7/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3561 - acc: 0.8652 - val_loss: 1.7615 - val_acc: 0.6444\n",
      "Epoch 8/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3647 - acc: 0.8499 - val_loss: 1.2032 - val_acc: 0.6222\n",
      "Epoch 9/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3476 - acc: 0.8676 - val_loss: 1.4980 - val_acc: 0.7111\n",
      "Epoch 10/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3557 - acc: 0.8617 - val_loss: 1.3699 - val_acc: 0.5556\n",
      "Epoch 11/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4008 - acc: 0.8463 - val_loss: 1.5852 - val_acc: 0.6667\n",
      "Epoch 12/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.3179 - acc: 0.8747 - val_loss: 1.5853 - val_acc: 0.5111\n",
      "Epoch 13/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4694 - acc: 0.8085 - val_loss: 1.4097 - val_acc: 0.6444\n",
      "Epoch 14/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3266 - acc: 0.8783 - val_loss: 1.7791 - val_acc: 0.6889\n",
      "Epoch 15/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4176 - acc: 0.8369 - val_loss: 1.3254 - val_acc: 0.6000\n",
      "Epoch 16/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3153 - acc: 0.8830 - val_loss: 1.4522 - val_acc: 0.6667\n",
      "Epoch 17/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3240 - acc: 0.8771 - val_loss: 1.2388 - val_acc: 0.6667\n",
      "Epoch 18/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3387 - acc: 0.8700 - val_loss: 1.3540 - val_acc: 0.6667\n",
      "Epoch 19/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3377 - acc: 0.8676 - val_loss: 1.8600 - val_acc: 0.6444\n",
      "Epoch 20/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.3347 - acc: 0.8593 - val_loss: 1.5021 - val_acc: 0.4889\n",
      "Epoch 21/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.4913 - acc: 0.7908 - val_loss: 1.6406 - val_acc: 0.6667\n",
      "Epoch 22/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2780 - acc: 0.8972 - val_loss: 1.3438 - val_acc: 0.6667\n",
      "Epoch 23/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3029 - acc: 0.8889 - val_loss: 1.4057 - val_acc: 0.5333\n",
      "Epoch 24/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3968 - acc: 0.8369 - val_loss: 1.1690 - val_acc: 0.6222\n",
      "Epoch 25/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2958 - acc: 0.8853 - val_loss: 1.2187 - val_acc: 0.6444\n",
      "Epoch 26/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3671 - acc: 0.8345 - val_loss: 1.1535 - val_acc: 0.6444\n",
      "Epoch 27/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2884 - acc: 0.8913 - val_loss: 1.6409 - val_acc: 0.6667\n",
      "Epoch 28/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3412 - acc: 0.8712 - val_loss: 1.3211 - val_acc: 0.5556\n",
      "Epoch 29/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3946 - acc: 0.8369 - val_loss: 1.5920 - val_acc: 0.6667\n",
      "Epoch 30/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3479 - acc: 0.8783 - val_loss: 1.1738 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.3055 - acc: 0.8676 - val_loss: 1.2259 - val_acc: 0.7111\n",
      "Epoch 32/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2829 - acc: 0.8913 - val_loss: 1.4708 - val_acc: 0.6667\n",
      "Epoch 33/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3084 - acc: 0.8759 - val_loss: 1.3848 - val_acc: 0.6667\n",
      "Epoch 34/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.4032 - acc: 0.8274 - val_loss: 1.5249 - val_acc: 0.7111\n",
      "Epoch 35/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2858 - acc: 0.8913 - val_loss: 1.4474 - val_acc: 0.7111\n",
      "Epoch 36/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2917 - acc: 0.8830 - val_loss: 1.3327 - val_acc: 0.7333\n",
      "Epoch 37/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3389 - acc: 0.8641 - val_loss: 1.4814 - val_acc: 0.6889\n",
      "Epoch 38/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3024 - acc: 0.8806 - val_loss: 1.8509 - val_acc: 0.6667\n",
      "Epoch 39/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3490 - acc: 0.8664 - val_loss: 1.6360 - val_acc: 0.6444\n",
      "Epoch 40/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3251 - acc: 0.8712 - val_loss: 1.9983 - val_acc: 0.6222\n",
      "Epoch 41/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.3309 - acc: 0.8664 - val_loss: 1.6389 - val_acc: 0.6889\n",
      "Epoch 42/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2631 - acc: 0.8948 - val_loss: 1.6677 - val_acc: 0.6667\n",
      "Epoch 43/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.3711 - acc: 0.8239 - val_loss: 1.4526 - val_acc: 0.6222\n",
      "Epoch 44/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2853 - acc: 0.8948 - val_loss: 2.0188 - val_acc: 0.6222\n",
      "Epoch 45/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2725 - acc: 0.8924 - val_loss: 1.2201 - val_acc: 0.7111\n",
      "Epoch 46/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.3111 - acc: 0.8723 - val_loss: 1.4625 - val_acc: 0.5556\n",
      "Epoch 47/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.4101 - acc: 0.8440 - val_loss: 1.3698 - val_acc: 0.6889\n",
      "Epoch 48/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2843 - acc: 0.8936 - val_loss: 1.6263 - val_acc: 0.6889\n",
      "Epoch 49/300\n",
      "846/846 [==============================] - 0s 25us/step - loss: 0.3152 - acc: 0.8735 - val_loss: 1.4274 - val_acc: 0.6889\n",
      "Epoch 50/300\n",
      "846/846 [==============================] - 0s 26us/step - loss: 0.2844 - acc: 0.8830 - val_loss: 1.6427 - val_acc: 0.6889\n",
      "Epoch 51/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2654 - acc: 0.8960 - val_loss: 1.7956 - val_acc: 0.6222\n",
      "Epoch 52/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4323 - acc: 0.8286 - val_loss: 1.6744 - val_acc: 0.7111\n",
      "Epoch 53/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.2968 - acc: 0.8818 - val_loss: 1.3877 - val_acc: 0.7333\n",
      "Epoch 54/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2568 - acc: 0.9090 - val_loss: 1.4011 - val_acc: 0.7111\n",
      "Epoch 55/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3522 - acc: 0.8463 - val_loss: 1.8560 - val_acc: 0.6667\n",
      "Epoch 56/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3502 - acc: 0.8700 - val_loss: 1.0540 - val_acc: 0.7111\n",
      "Epoch 57/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2634 - acc: 0.9054 - val_loss: 1.3436 - val_acc: 0.6000\n",
      "Epoch 58/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3278 - acc: 0.8676 - val_loss: 1.6081 - val_acc: 0.6222\n",
      "Epoch 59/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2936 - acc: 0.8842 - val_loss: 1.4340 - val_acc: 0.6667\n",
      "Epoch 60/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2819 - acc: 0.8865 - val_loss: 1.0519 - val_acc: 0.6000\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846/846 [==============================] - 0s 20us/step - loss: 0.3418 - acc: 0.8641 - val_loss: 1.4506 - val_acc: 0.6444\n",
      "Epoch 62/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2979 - acc: 0.8818 - val_loss: 1.7340 - val_acc: 0.6889\n",
      "Epoch 63/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3421 - acc: 0.8617 - val_loss: 1.2838 - val_acc: 0.6222\n",
      "Epoch 64/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3420 - acc: 0.8759 - val_loss: 1.2678 - val_acc: 0.6444\n",
      "Epoch 65/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2630 - acc: 0.9019 - val_loss: 1.6763 - val_acc: 0.6667\n",
      "Epoch 66/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3022 - acc: 0.8924 - val_loss: 1.3474 - val_acc: 0.6444\n",
      "Epoch 67/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2939 - acc: 0.8901 - val_loss: 1.0989 - val_acc: 0.6889\n",
      "Epoch 68/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3771 - acc: 0.8676 - val_loss: 1.5323 - val_acc: 0.7111\n",
      "Epoch 69/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2804 - acc: 0.9019 - val_loss: 1.5310 - val_acc: 0.5556\n",
      "Epoch 70/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3062 - acc: 0.8712 - val_loss: 1.7352 - val_acc: 0.7111\n",
      "Epoch 71/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3231 - acc: 0.8759 - val_loss: 1.6581 - val_acc: 0.6000\n",
      "Epoch 72/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2887 - acc: 0.8806 - val_loss: 1.7223 - val_acc: 0.7111\n",
      "Epoch 73/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2667 - acc: 0.8913 - val_loss: 1.3055 - val_acc: 0.6889\n",
      "Epoch 74/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2628 - acc: 0.9043 - val_loss: 1.6492 - val_acc: 0.7111\n",
      "Epoch 75/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2494 - acc: 0.9031 - val_loss: 1.5190 - val_acc: 0.6889\n",
      "Epoch 76/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2917 - acc: 0.8759 - val_loss: 1.4391 - val_acc: 0.6222\n",
      "Epoch 77/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3842 - acc: 0.8392 - val_loss: 1.2284 - val_acc: 0.6667\n",
      "Epoch 78/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2984 - acc: 0.8818 - val_loss: 1.5126 - val_acc: 0.6444\n",
      "Epoch 79/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2609 - acc: 0.8948 - val_loss: 1.3757 - val_acc: 0.6667\n",
      "Epoch 80/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2695 - acc: 0.8936 - val_loss: 1.0801 - val_acc: 0.7111\n",
      "Epoch 81/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2956 - acc: 0.8783 - val_loss: 1.8254 - val_acc: 0.6222\n",
      "Epoch 82/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2837 - acc: 0.8889 - val_loss: 1.3060 - val_acc: 0.6667\n",
      "Epoch 83/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2610 - acc: 0.9031 - val_loss: 1.7313 - val_acc: 0.6222\n",
      "Epoch 84/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.4254 - acc: 0.8132 - val_loss: 1.3994 - val_acc: 0.7333\n",
      "Epoch 85/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2660 - acc: 0.9019 - val_loss: 1.4186 - val_acc: 0.7111\n",
      "Epoch 86/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2312 - acc: 0.9196 - val_loss: 1.6752 - val_acc: 0.6222\n",
      "Epoch 87/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2630 - acc: 0.8936 - val_loss: 1.2945 - val_acc: 0.6889\n",
      "Epoch 88/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3615 - acc: 0.8605 - val_loss: 2.2737 - val_acc: 0.6889\n",
      "Epoch 89/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3099 - acc: 0.8806 - val_loss: 1.7769 - val_acc: 0.5333\n",
      "Epoch 90/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2913 - acc: 0.8830 - val_loss: 1.4216 - val_acc: 0.6667\n",
      "Epoch 91/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2388 - acc: 0.9043 - val_loss: 1.3901 - val_acc: 0.6889\n",
      "Epoch 92/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2397 - acc: 0.9066 - val_loss: 1.5337 - val_acc: 0.7111\n",
      "Epoch 93/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2619 - acc: 0.8960 - val_loss: 1.3765 - val_acc: 0.6889\n",
      "Epoch 94/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2435 - acc: 0.8901 - val_loss: 1.6176 - val_acc: 0.6889\n",
      "Epoch 95/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2901 - acc: 0.8853 - val_loss: 1.3961 - val_acc: 0.6000\n",
      "Epoch 96/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3685 - acc: 0.8369 - val_loss: 1.4394 - val_acc: 0.6889\n",
      "Epoch 97/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2302 - acc: 0.9102 - val_loss: 1.1998 - val_acc: 0.6889\n",
      "Epoch 98/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2310 - acc: 0.9007 - val_loss: 1.8251 - val_acc: 0.6000\n",
      "Epoch 99/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2512 - acc: 0.9031 - val_loss: 1.5421 - val_acc: 0.6222\n",
      "Epoch 100/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2431 - acc: 0.8913 - val_loss: 1.8184 - val_acc: 0.6444\n",
      "Epoch 101/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2816 - acc: 0.8889 - val_loss: 1.3075 - val_acc: 0.7333\n",
      "Epoch 102/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3200 - acc: 0.8759 - val_loss: 1.2409 - val_acc: 0.7111\n",
      "Epoch 103/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2283 - acc: 0.8995 - val_loss: 1.8463 - val_acc: 0.6222\n",
      "Epoch 104/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.2695 - acc: 0.8865 - val_loss: 1.3810 - val_acc: 0.5778\n",
      "Epoch 105/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.2911 - acc: 0.8712 - val_loss: 1.6113 - val_acc: 0.6667\n",
      "Epoch 106/300\n",
      "846/846 [==============================] - ETA: 0s - loss: 0.2230 - acc: 0.905 - 0s 22us/step - loss: 0.2313 - acc: 0.9031 - val_loss: 1.3606 - val_acc: 0.6444\n",
      "Epoch 107/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2323 - acc: 0.9043 - val_loss: 1.4008 - val_acc: 0.5111\n",
      "Epoch 108/300\n",
      "846/846 [==============================] - 0s 24us/step - loss: 0.2841 - acc: 0.8830 - val_loss: 1.7478 - val_acc: 0.6444\n",
      "Epoch 109/300\n",
      "846/846 [==============================] - 0s 24us/step - loss: 0.2203 - acc: 0.9054 - val_loss: 1.5353 - val_acc: 0.6667\n",
      "Epoch 110/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2968 - acc: 0.8676 - val_loss: 1.2202 - val_acc: 0.7333\n",
      "Epoch 111/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2227 - acc: 0.9125 - val_loss: 1.1528 - val_acc: 0.6667\n",
      "Epoch 112/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3425 - acc: 0.8499 - val_loss: 1.2199 - val_acc: 0.6889\n",
      "Epoch 113/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2749 - acc: 0.8818 - val_loss: 1.9144 - val_acc: 0.6444\n",
      "Epoch 114/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.2124 - acc: 0.9173 - val_loss: 1.6411 - val_acc: 0.7111\n",
      "Epoch 115/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2214 - acc: 0.9031 - val_loss: 1.5767 - val_acc: 0.6000\n",
      "Epoch 116/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2953 - acc: 0.8783 - val_loss: 1.3004 - val_acc: 0.6667\n",
      "Epoch 117/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2754 - acc: 0.8842 - val_loss: 1.2766 - val_acc: 0.7333\n",
      "Epoch 118/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2017 - acc: 0.9149 - val_loss: 1.5822 - val_acc: 0.6444\n",
      "Epoch 119/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2727 - acc: 0.8806 - val_loss: 1.9953 - val_acc: 0.6667\n",
      "Epoch 120/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2609 - acc: 0.8853 - val_loss: 1.5021 - val_acc: 0.7111\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846/846 [==============================] - 0s 22us/step - loss: 0.2209 - acc: 0.9113 - val_loss: 1.5843 - val_acc: 0.7111\n",
      "Epoch 122/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2406 - acc: 0.8948 - val_loss: 1.4577 - val_acc: 0.6667\n",
      "Epoch 123/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2605 - acc: 0.8889 - val_loss: 1.4657 - val_acc: 0.7111\n",
      "Epoch 124/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3100 - acc: 0.8641 - val_loss: 1.6051 - val_acc: 0.6889\n",
      "Epoch 125/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.3144 - acc: 0.8641 - val_loss: 1.5144 - val_acc: 0.6444\n",
      "Epoch 126/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2163 - acc: 0.9161 - val_loss: 1.6294 - val_acc: 0.6667\n",
      "Epoch 127/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2128 - acc: 0.9196 - val_loss: 1.4604 - val_acc: 0.7333\n",
      "Epoch 128/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2543 - acc: 0.8948 - val_loss: 1.7283 - val_acc: 0.6444\n",
      "Epoch 129/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3105 - acc: 0.8783 - val_loss: 1.6705 - val_acc: 0.6444\n",
      "Epoch 130/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2140 - acc: 0.9208 - val_loss: 1.4584 - val_acc: 0.6889\n",
      "Epoch 131/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2538 - acc: 0.8877 - val_loss: 1.8897 - val_acc: 0.5778\n",
      "Epoch 132/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2880 - acc: 0.8771 - val_loss: 1.4955 - val_acc: 0.6222\n",
      "Epoch 133/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2684 - acc: 0.8664 - val_loss: 1.7689 - val_acc: 0.6444\n",
      "Epoch 134/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2312 - acc: 0.9007 - val_loss: 1.6022 - val_acc: 0.6889\n",
      "Epoch 135/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2009 - acc: 0.9220 - val_loss: 1.5882 - val_acc: 0.7333\n",
      "Epoch 136/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2276 - acc: 0.9149 - val_loss: 1.8978 - val_acc: 0.6667\n",
      "Epoch 137/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2940 - acc: 0.8700 - val_loss: 1.4282 - val_acc: 0.6667\n",
      "Epoch 138/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2291 - acc: 0.9090 - val_loss: 1.5001 - val_acc: 0.6889\n",
      "Epoch 139/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2004 - acc: 0.9291 - val_loss: 1.5007 - val_acc: 0.7111\n",
      "Epoch 140/300\n",
      "846/846 [==============================] - ETA: 0s - loss: 0.2679 - acc: 0.885 - 0s 23us/step - loss: 0.2217 - acc: 0.9102 - val_loss: 1.4888 - val_acc: 0.6222\n",
      "Epoch 141/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.2816 - acc: 0.8794 - val_loss: 1.6753 - val_acc: 0.6000\n",
      "Epoch 142/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2506 - acc: 0.8972 - val_loss: 1.7419 - val_acc: 0.6222\n",
      "Epoch 143/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2305 - acc: 0.9007 - val_loss: 1.5475 - val_acc: 0.6889\n",
      "Epoch 144/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2756 - acc: 0.8865 - val_loss: 1.6822 - val_acc: 0.6667\n",
      "Epoch 145/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2506 - acc: 0.9043 - val_loss: 1.4671 - val_acc: 0.7111\n",
      "Epoch 146/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1917 - acc: 0.9255 - val_loss: 1.6514 - val_acc: 0.7333\n",
      "Epoch 147/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2319 - acc: 0.8948 - val_loss: 1.5993 - val_acc: 0.5556\n",
      "Epoch 148/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2806 - acc: 0.8783 - val_loss: 1.6463 - val_acc: 0.6889\n",
      "Epoch 149/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2050 - acc: 0.9243 - val_loss: 1.6695 - val_acc: 0.7111\n",
      "Epoch 150/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2744 - acc: 0.8877 - val_loss: 1.6170 - val_acc: 0.6667\n",
      "Epoch 151/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1971 - acc: 0.9232 - val_loss: 1.6978 - val_acc: 0.6667\n",
      "Epoch 152/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2108 - acc: 0.9161 - val_loss: 1.7553 - val_acc: 0.6444\n",
      "Epoch 153/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2109 - acc: 0.9125 - val_loss: 1.6035 - val_acc: 0.6889\n",
      "Epoch 154/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2851 - acc: 0.8771 - val_loss: 2.1418 - val_acc: 0.6667\n",
      "Epoch 155/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3086 - acc: 0.8889 - val_loss: 1.9612 - val_acc: 0.6667\n",
      "Epoch 156/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.1965 - acc: 0.9267 - val_loss: 1.6872 - val_acc: 0.6889\n",
      "Epoch 157/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1878 - acc: 0.9314 - val_loss: 1.8239 - val_acc: 0.7111\n",
      "Epoch 158/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2214 - acc: 0.9043 - val_loss: 1.6792 - val_acc: 0.6889\n",
      "Epoch 159/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2169 - acc: 0.9078 - val_loss: 2.2784 - val_acc: 0.6444\n",
      "Epoch 160/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.3605 - acc: 0.8723 - val_loss: 1.9523 - val_acc: 0.6222\n",
      "Epoch 161/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2088 - acc: 0.9196 - val_loss: 1.5532 - val_acc: 0.6667\n",
      "Epoch 162/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2004 - acc: 0.9243 - val_loss: 1.6125 - val_acc: 0.6667\n",
      "Epoch 163/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2116 - acc: 0.9173 - val_loss: 1.2676 - val_acc: 0.7333\n",
      "Epoch 164/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2692 - acc: 0.8842 - val_loss: 2.0152 - val_acc: 0.6667\n",
      "Epoch 165/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2501 - acc: 0.8889 - val_loss: 1.5910 - val_acc: 0.7111\n",
      "Epoch 166/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2125 - acc: 0.9102 - val_loss: 1.6169 - val_acc: 0.6889\n",
      "Epoch 167/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2393 - acc: 0.9019 - val_loss: 1.5977 - val_acc: 0.6667\n",
      "Epoch 168/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2082 - acc: 0.9090 - val_loss: 1.5019 - val_acc: 0.7111\n",
      "Epoch 169/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1889 - acc: 0.9149 - val_loss: 1.6625 - val_acc: 0.6889\n",
      "Epoch 170/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.3236 - acc: 0.8676 - val_loss: 1.7480 - val_acc: 0.7111\n",
      "Epoch 171/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2711 - acc: 0.8995 - val_loss: 1.6706 - val_acc: 0.6667\n",
      "Epoch 172/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1903 - acc: 0.9303 - val_loss: 1.6105 - val_acc: 0.7111\n",
      "Epoch 173/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2072 - acc: 0.9173 - val_loss: 1.6889 - val_acc: 0.7111\n",
      "Epoch 174/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2484 - acc: 0.8948 - val_loss: 1.3602 - val_acc: 0.6667\n",
      "Epoch 175/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2145 - acc: 0.9220 - val_loss: 1.6858 - val_acc: 0.7111\n",
      "Epoch 176/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.1946 - acc: 0.9196 - val_loss: 1.8239 - val_acc: 0.6667\n",
      "Epoch 177/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2699 - acc: 0.8913 - val_loss: 1.4111 - val_acc: 0.6000\n",
      "Epoch 178/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2741 - acc: 0.8794 - val_loss: 1.4493 - val_acc: 0.6000\n",
      "Epoch 179/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2267 - acc: 0.9078 - val_loss: 1.5642 - val_acc: 0.6444\n",
      "Epoch 180/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1827 - acc: 0.9255 - val_loss: 1.5456 - val_acc: 0.7111\n",
      "Epoch 181/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846/846 [==============================] - 0s 21us/step - loss: 0.2242 - acc: 0.9007 - val_loss: 1.6114 - val_acc: 0.7333\n",
      "Epoch 182/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1957 - acc: 0.9255 - val_loss: 1.5196 - val_acc: 0.7556\n",
      "Epoch 183/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2186 - acc: 0.9125 - val_loss: 2.2770 - val_acc: 0.6444\n",
      "Epoch 184/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.4312 - acc: 0.8511 - val_loss: 1.5182 - val_acc: 0.6000\n",
      "Epoch 185/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2527 - acc: 0.8924 - val_loss: 1.5949 - val_acc: 0.6889\n",
      "Epoch 186/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1775 - acc: 0.9350 - val_loss: 1.6363 - val_acc: 0.6222\n",
      "Epoch 187/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2028 - acc: 0.9208 - val_loss: 1.9064 - val_acc: 0.6667\n",
      "Epoch 188/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2317 - acc: 0.9031 - val_loss: 1.9157 - val_acc: 0.6667\n",
      "Epoch 189/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1947 - acc: 0.9173 - val_loss: 1.7874 - val_acc: 0.7111\n",
      "Epoch 190/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2237 - acc: 0.8960 - val_loss: 1.8691 - val_acc: 0.6444\n",
      "Epoch 191/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1912 - acc: 0.9255 - val_loss: 1.8970 - val_acc: 0.6889\n",
      "Epoch 192/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2811 - acc: 0.8936 - val_loss: 1.4908 - val_acc: 0.6667\n",
      "Epoch 193/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2261 - acc: 0.9031 - val_loss: 2.3696 - val_acc: 0.6222\n",
      "Epoch 194/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2059 - acc: 0.9196 - val_loss: 1.5329 - val_acc: 0.7111\n",
      "Epoch 195/300\n",
      "846/846 [==============================] - 0s 24us/step - loss: 0.2657 - acc: 0.8842 - val_loss: 1.8456 - val_acc: 0.7111\n",
      "Epoch 196/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1992 - acc: 0.9196 - val_loss: 1.7268 - val_acc: 0.6889\n",
      "Epoch 197/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2291 - acc: 0.9019 - val_loss: 1.8713 - val_acc: 0.6889\n",
      "Epoch 198/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1875 - acc: 0.9314 - val_loss: 1.7797 - val_acc: 0.7111\n",
      "Epoch 199/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2115 - acc: 0.9149 - val_loss: 1.9117 - val_acc: 0.6889\n",
      "Epoch 200/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2169 - acc: 0.9125 - val_loss: 1.8261 - val_acc: 0.6889\n",
      "Epoch 201/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1830 - acc: 0.9232 - val_loss: 1.7430 - val_acc: 0.6667\n",
      "Epoch 202/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2660 - acc: 0.8783 - val_loss: 1.4513 - val_acc: 0.6444\n",
      "Epoch 203/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2039 - acc: 0.9232 - val_loss: 2.0329 - val_acc: 0.6444\n",
      "Epoch 204/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2469 - acc: 0.8794 - val_loss: 1.5919 - val_acc: 0.7333\n",
      "Epoch 205/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1875 - acc: 0.9208 - val_loss: 1.6125 - val_acc: 0.6889\n",
      "Epoch 206/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2008 - acc: 0.9220 - val_loss: 1.7701 - val_acc: 0.6889\n",
      "Epoch 207/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2638 - acc: 0.8960 - val_loss: 1.7515 - val_acc: 0.6667\n",
      "Epoch 208/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2376 - acc: 0.9007 - val_loss: 1.5687 - val_acc: 0.6667\n",
      "Epoch 209/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1758 - acc: 0.9326 - val_loss: 1.9316 - val_acc: 0.7333\n",
      "Epoch 210/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1821 - acc: 0.9243 - val_loss: 2.0403 - val_acc: 0.6444\n",
      "Epoch 211/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2282 - acc: 0.9125 - val_loss: 1.5765 - val_acc: 0.7333\n",
      "Epoch 212/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2156 - acc: 0.9090 - val_loss: 1.7795 - val_acc: 0.6889\n",
      "Epoch 213/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2010 - acc: 0.9314 - val_loss: 1.9429 - val_acc: 0.7111\n",
      "Epoch 214/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2510 - acc: 0.9149 - val_loss: 1.3656 - val_acc: 0.6889\n",
      "Epoch 215/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2690 - acc: 0.8960 - val_loss: 1.8511 - val_acc: 0.6889\n",
      "Epoch 216/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2036 - acc: 0.9125 - val_loss: 1.4883 - val_acc: 0.7556\n",
      "Epoch 217/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1928 - acc: 0.9208 - val_loss: 1.6147 - val_acc: 0.6667\n",
      "Epoch 218/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1803 - acc: 0.9208 - val_loss: 1.4687 - val_acc: 0.6444\n",
      "Epoch 219/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2545 - acc: 0.8913 - val_loss: 1.7399 - val_acc: 0.7111\n",
      "Epoch 220/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2307 - acc: 0.8972 - val_loss: 1.8661 - val_acc: 0.6889\n",
      "Epoch 221/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2151 - acc: 0.9125 - val_loss: 1.6561 - val_acc: 0.6667\n",
      "Epoch 222/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2133 - acc: 0.9243 - val_loss: 1.5122 - val_acc: 0.6889\n",
      "Epoch 223/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1673 - acc: 0.9397 - val_loss: 1.8716 - val_acc: 0.6889\n",
      "Epoch 224/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2435 - acc: 0.9090 - val_loss: 1.7847 - val_acc: 0.6444\n",
      "Epoch 225/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2014 - acc: 0.9113 - val_loss: 1.5521 - val_acc: 0.6889\n",
      "Epoch 226/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2458 - acc: 0.9043 - val_loss: 1.2365 - val_acc: 0.6889\n",
      "Epoch 227/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1707 - acc: 0.9421 - val_loss: 1.4105 - val_acc: 0.6889\n",
      "Epoch 228/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1921 - acc: 0.9279 - val_loss: 2.4295 - val_acc: 0.6667\n",
      "Epoch 229/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2404 - acc: 0.9054 - val_loss: 1.6626 - val_acc: 0.7333\n",
      "Epoch 230/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1933 - acc: 0.9232 - val_loss: 1.8398 - val_acc: 0.6889\n",
      "Epoch 231/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.1823 - acc: 0.9362 - val_loss: 1.6474 - val_acc: 0.6444\n",
      "Epoch 232/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2224 - acc: 0.9113 - val_loss: 2.0571 - val_acc: 0.6667\n",
      "Epoch 233/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1972 - acc: 0.9137 - val_loss: 1.6642 - val_acc: 0.7111\n",
      "Epoch 234/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1911 - acc: 0.9338 - val_loss: 1.6376 - val_acc: 0.6889\n",
      "Epoch 235/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2234 - acc: 0.9102 - val_loss: 1.9848 - val_acc: 0.6444\n",
      "Epoch 236/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.2346 - acc: 0.8924 - val_loss: 1.6790 - val_acc: 0.6889\n",
      "Epoch 237/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1992 - acc: 0.9232 - val_loss: 2.2493 - val_acc: 0.7111\n",
      "Epoch 238/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1947 - acc: 0.9208 - val_loss: 1.9308 - val_acc: 0.6444\n",
      "Epoch 239/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1664 - acc: 0.9350 - val_loss: 1.6056 - val_acc: 0.7111\n",
      "Epoch 240/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2151 - acc: 0.9031 - val_loss: 1.8449 - val_acc: 0.7333\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846/846 [==============================] - 0s 21us/step - loss: 0.1870 - acc: 0.9267 - val_loss: 2.1454 - val_acc: 0.6889\n",
      "Epoch 242/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1791 - acc: 0.9338 - val_loss: 1.7303 - val_acc: 0.6667\n",
      "Epoch 243/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1880 - acc: 0.9208 - val_loss: 2.1524 - val_acc: 0.6444\n",
      "Epoch 244/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2202 - acc: 0.9173 - val_loss: 1.9720 - val_acc: 0.6667\n",
      "Epoch 245/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.1649 - acc: 0.9433 - val_loss: 1.4541 - val_acc: 0.6222\n",
      "Epoch 246/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2803 - acc: 0.8818 - val_loss: 1.8613 - val_acc: 0.6889\n",
      "Epoch 247/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1752 - acc: 0.9314 - val_loss: 1.4723 - val_acc: 0.6889\n",
      "Epoch 248/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1762 - acc: 0.9243 - val_loss: 1.6887 - val_acc: 0.7333\n",
      "Epoch 249/300\n",
      "846/846 [==============================] - 0s 23us/step - loss: 0.1773 - acc: 0.9303 - val_loss: 1.8592 - val_acc: 0.7333\n",
      "Epoch 250/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2030 - acc: 0.9208 - val_loss: 2.0032 - val_acc: 0.6667\n",
      "Epoch 251/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2874 - acc: 0.8783 - val_loss: 1.8924 - val_acc: 0.7111\n",
      "Epoch 252/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1675 - acc: 0.9421 - val_loss: 1.6897 - val_acc: 0.6444\n",
      "Epoch 253/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1893 - acc: 0.9243 - val_loss: 1.6221 - val_acc: 0.7111\n",
      "Epoch 254/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1739 - acc: 0.9326 - val_loss: 1.9073 - val_acc: 0.6444\n",
      "Epoch 255/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2863 - acc: 0.8865 - val_loss: 2.0231 - val_acc: 0.6889\n",
      "Epoch 256/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2000 - acc: 0.9220 - val_loss: 1.7090 - val_acc: 0.6889\n",
      "Epoch 257/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1538 - acc: 0.9409 - val_loss: 1.8112 - val_acc: 0.7111\n",
      "Epoch 258/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2274 - acc: 0.9078 - val_loss: 2.0089 - val_acc: 0.7111\n",
      "Epoch 259/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1596 - acc: 0.9314 - val_loss: 1.6068 - val_acc: 0.7111\n",
      "Epoch 260/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1962 - acc: 0.9243 - val_loss: 2.0186 - val_acc: 0.6667\n",
      "Epoch 261/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1612 - acc: 0.9385 - val_loss: 2.1367 - val_acc: 0.6889\n",
      "Epoch 262/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2655 - acc: 0.8972 - val_loss: 1.9810 - val_acc: 0.7333\n",
      "Epoch 263/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1960 - acc: 0.9173 - val_loss: 1.7915 - val_acc: 0.7333\n",
      "Epoch 264/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2000 - acc: 0.9184 - val_loss: 1.6467 - val_acc: 0.7333\n",
      "Epoch 265/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2271 - acc: 0.9161 - val_loss: 1.5660 - val_acc: 0.7111\n",
      "Epoch 266/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1544 - acc: 0.9444 - val_loss: 1.7683 - val_acc: 0.6667\n",
      "Epoch 267/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1547 - acc: 0.9433 - val_loss: 1.9652 - val_acc: 0.7111\n",
      "Epoch 268/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2670 - acc: 0.9019 - val_loss: 1.6163 - val_acc: 0.6222\n",
      "Epoch 269/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.2237 - acc: 0.9149 - val_loss: 1.9671 - val_acc: 0.6889\n",
      "Epoch 270/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1508 - acc: 0.9433 - val_loss: 1.8873 - val_acc: 0.6444\n",
      "Epoch 271/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1971 - acc: 0.9243 - val_loss: 1.7599 - val_acc: 0.6889\n",
      "Epoch 272/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1593 - acc: 0.9421 - val_loss: 2.0296 - val_acc: 0.7333\n",
      "Epoch 273/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1856 - acc: 0.9303 - val_loss: 1.5910 - val_acc: 0.6889\n",
      "Epoch 274/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2463 - acc: 0.9090 - val_loss: 1.6279 - val_acc: 0.6889\n",
      "Epoch 275/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1906 - acc: 0.9232 - val_loss: 1.6998 - val_acc: 0.7333\n",
      "Epoch 276/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1693 - acc: 0.9362 - val_loss: 2.0061 - val_acc: 0.6667\n",
      "Epoch 277/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1694 - acc: 0.9338 - val_loss: 1.4880 - val_acc: 0.6444\n",
      "Epoch 278/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2014 - acc: 0.9125 - val_loss: 1.6416 - val_acc: 0.6444\n",
      "Epoch 279/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2111 - acc: 0.9054 - val_loss: 1.6808 - val_acc: 0.6889\n",
      "Epoch 280/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1745 - acc: 0.9350 - val_loss: 1.8257 - val_acc: 0.7111\n",
      "Epoch 281/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1611 - acc: 0.9385 - val_loss: 2.4534 - val_acc: 0.7111\n",
      "Epoch 282/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2546 - acc: 0.9019 - val_loss: 1.4767 - val_acc: 0.6889\n",
      "Epoch 283/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1775 - acc: 0.9303 - val_loss: 2.0784 - val_acc: 0.6889\n",
      "Epoch 284/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2207 - acc: 0.9291 - val_loss: 1.5350 - val_acc: 0.7111\n",
      "Epoch 285/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1726 - acc: 0.9267 - val_loss: 1.8102 - val_acc: 0.6444\n",
      "Epoch 286/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1696 - acc: 0.9338 - val_loss: 1.8742 - val_acc: 0.6889\n",
      "Epoch 287/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.2036 - acc: 0.9243 - val_loss: 1.9419 - val_acc: 0.6444\n",
      "Epoch 288/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1778 - acc: 0.9338 - val_loss: 1.8867 - val_acc: 0.6889\n",
      "Epoch 289/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.1641 - acc: 0.9314 - val_loss: 2.0143 - val_acc: 0.6889\n",
      "Epoch 290/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1471 - acc: 0.9551 - val_loss: 1.2765 - val_acc: 0.7111\n",
      "Epoch 291/300\n",
      "846/846 [==============================] - 0s 19us/step - loss: 0.3812 - acc: 0.8605 - val_loss: 1.6719 - val_acc: 0.7333\n",
      "Epoch 292/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1489 - acc: 0.9527 - val_loss: 2.0176 - val_acc: 0.6222\n",
      "Epoch 293/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1529 - acc: 0.9504 - val_loss: 1.6865 - val_acc: 0.6444\n",
      "Epoch 294/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1722 - acc: 0.9255 - val_loss: 2.0134 - val_acc: 0.6889\n",
      "Epoch 295/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1722 - acc: 0.9314 - val_loss: 2.1913 - val_acc: 0.6667\n",
      "Epoch 296/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1769 - acc: 0.9326 - val_loss: 1.9991 - val_acc: 0.6889\n",
      "Epoch 297/300\n",
      "846/846 [==============================] - 0s 20us/step - loss: 0.1465 - acc: 0.9468 - val_loss: 1.6752 - val_acc: 0.6000\n",
      "Epoch 298/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.2635 - acc: 0.8972 - val_loss: 1.5875 - val_acc: 0.6889\n",
      "Epoch 299/300\n",
      "846/846 [==============================] - 0s 22us/step - loss: 0.1527 - acc: 0.9527 - val_loss: 1.7469 - val_acc: 0.7111\n",
      "Epoch 300/300\n",
      "846/846 [==============================] - 0s 21us/step - loss: 0.1630 - acc: 0.9385 - val_loss: 1.6564 - val_acc: 0.7111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x162f61497f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y),\n",
    "          epochs=300, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31933616375356244, 0.8903566713062271]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_x, train_y, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
